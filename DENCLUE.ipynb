{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#-*-coding:utf-8-*-\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClusterMixin\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from PIL import  Image\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xlwt  # 负责写excel\n",
    "import xlrd\n",
    "\n",
    "#爬坡\n",
    "def _hill_climb(x_t, X, W=None, h=0.1, eps=1e-7):\n",
    "    error = 99.\n",
    "    prob = 0.\n",
    "    x_l1 = np.copy(x_t)   #X(t+1)\n",
    "    radius_new = 0.\n",
    "    radius_old = 0.\n",
    "    radius_twiceold = 0.\n",
    "    iters = 0.\n",
    "    while True:\n",
    "        radius_thriceold = radius_twiceold\n",
    "        radius_twiceold = radius_old\n",
    "        radius_old = radius_new\n",
    "        x_l0 = np.copy(x_l1)       #X(t)\n",
    "        x_l1, density = _step(x_l0, X, W=W, h=h)\n",
    "        error = density - prob\n",
    "        prob = density\n",
    "        radius_new = np.linalg.norm(x_l1 - x_l0)\n",
    "        radius = radius_thriceold + radius_twiceold + radius_old + radius_new\n",
    "        iters += 1\n",
    "        if iters > 3 and error < eps:\n",
    "            break\n",
    "    return [x_l1, prob, radius]\n",
    "\n",
    "#计算X(t+1)\n",
    "def _step(x_l0, X, W=None, h=0.1):\n",
    "    n = X.shape[0]\n",
    "    d = X.shape[1]\n",
    "    superweight = 0.  # superweight is the kernel X weight for each item\n",
    "    x_l1 = np.zeros((1, d))\n",
    "    if W is None:\n",
    "        W = np.ones((n, 1))\n",
    "    else:\n",
    "        W = W\n",
    "    for j in range(n):\n",
    "        kernel = kernelize(x_l0, X[j], h, d)\n",
    "        kernel = kernel * W[j] / (h ** d)\n",
    "        superweight = superweight + kernel\n",
    "        x_l1 = x_l1 + (kernel * X[j])\n",
    "    x_l1 = x_l1 / superweight\n",
    "    density = superweight / np.sum(W)\n",
    "    return [x_l1, density]\n",
    "\n",
    "#计算高斯核\n",
    "def kernelize(x, y, h, degree):\n",
    "    kernel = np.exp(-(np.linalg.norm(x - y) / h) ** 2. / 2.) / ((2. * np.pi) ** (degree / 2))\n",
    "    return kernel\n",
    "#bad code\n",
    "'''def density(X,D,h,degree):\n",
    "    sum1=0\n",
    "    for i in range(D.shape[0]):\n",
    "        k=kernelize(X,D[i],h,degree)\n",
    "        sum1=sum1+k\n",
    "    d=1./D.shape[0]/h**degree*sum1\n",
    "    return d\n",
    "def DENCLUE(D,h,xi,eps):\n",
    "    rows=D.shape[0]\n",
    "   A=np.zeros((rows,D.shape[1]))\n",
    "    labels=-np.ones(rows)\n",
    "    dens = np.zeros((rows, 1))\n",
    "    degree = D.shape[1]\n",
    "    for i in range(rows):\n",
    "        x_mark=findattractor(D[i],D,h,eps)\n",
    "        dens[i]=density(x_mark,D,h,degree)\n",
    "        if dens[i]>=xi:\n",
    "            A[i]=x_mark\n",
    "    print A,dens\n",
    "'''\n",
    "class DENCLUE(BaseEstimator, ClusterMixin):\n",
    "    def __init__(self, h=None, eps=1e-8, min_density=0., metric='euclidean'):\n",
    "        self.h = h\n",
    "        self.eps = eps\n",
    "        self.min_density = min_density\n",
    "        self.metric = metric\n",
    "\n",
    "    def classify(self, X, y=None, sample_weight=None):\n",
    "        if not self.eps > 0.0:\n",
    "            raise ValueError(\"eps must be positive.\")\n",
    "        self.n_samples = X.shape[0]\n",
    "        self.n_features =X.shape[1]\n",
    "        density_attractors = np.zeros((self.n_samples, self.n_features))\n",
    "        radii = np.zeros((self.n_samples, 1))\n",
    "        density = np.zeros((self.n_samples, 1))\n",
    "\n",
    "        # 构造初始值\n",
    "        if self.h is None:\n",
    "            self.h = np.std(X) / 5\n",
    "        if sample_weight is None:\n",
    "            sample_weight = np.ones((self.n_samples, 1))\n",
    "        else:\n",
    "            sample_weight = sample_weight\n",
    "        # 初始化所有的点为noise点\n",
    "        labels = -np.ones(X.shape[0])\n",
    "        # 对每个样本点进行attractor和其相应密度的计算\n",
    "        for i in range(self.n_samples):\n",
    "            density_attractors[i], density[i], radii[i] = _hill_climb(X[i], X, W=sample_weight,\n",
    "                                                                      h=self.h, eps=self.eps)\n",
    "        # 构造链接图\n",
    "        cluster_info = {}\n",
    "        num_clusters = 0\n",
    "        cluster_info[num_clusters] = {'instances': [0],\n",
    "                                      'centroid': np.atleast_2d(density_attractors[0])}\n",
    "        g_clusters = nx.Graph()\n",
    "        for j1 in range(self.n_samples):\n",
    "            g_clusters.add_node(j1, attr_dict={'attractor': density_attractors[j1], 'radius': radii[j1],\n",
    "                                               'density': density[j1]})\n",
    "        # 构造聚类图\n",
    "        for j1 in range(self.n_samples):\n",
    "            for j2 in (x for x in range(self.n_samples) if x != j1):\n",
    "                if g_clusters.has_edge(j1, j2):\n",
    "                    continue\n",
    "                diff = np.linalg.norm(g_clusters.node[j1]['attr_dict']['attractor'] - g_clusters.node[j2]['attr_dict']['attractor'])\n",
    "                if diff <= (g_clusters.node[j1]['attr_dict']['radius'] + g_clusters.node[j1]['attr_dict']['radius']):\n",
    "                    g_clusters.add_edge(j1, j2)\n",
    "        clusters = list(nx.connected_component_subgraphs(g_clusters))\n",
    "        num_clusters = 0\n",
    "        # 链接聚类\n",
    "        for clust in clusters:\n",
    "            # 得到attractors中的最大密度以及相应的点位信息\n",
    "            max_instance = max(clust, key=lambda x: clust.node[x]['attr_dict']['density'])\n",
    "            max_density = clust.node[max_instance]['attr_dict']['density']\n",
    "            max_centroid = clust.node[max_instance]['attr_dict']['attractor']\n",
    "            complete = False\n",
    "            c_size = len(clust.nodes())\n",
    "            if clust.number_of_edges() == (c_size * (c_size - 1)) / 2.:\n",
    "                complete = True\n",
    "            # 构造聚类字典\n",
    "            cluster_info[num_clusters] = {'instances': clust.nodes(),\n",
    "                                          'size': c_size,\n",
    "                                          'centroid': max_centroid,\n",
    "                                          'density': max_density,\n",
    "                                          'complete': complete}\n",
    "            # 如果类的密度小于要求，则即为noise点\n",
    "            if max_density >= self.min_density:\n",
    "                labels[clust.nodes()] = num_clusters\n",
    "            num_clusters += 1\n",
    "        self.clust_info_ = cluster_info\n",
    "        self.labels_ = labels\n",
    "        return self\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1 (1).jpg' '1 (10).jpg' '1 (100).jpg' '1 (11).jpg' '1 (12).jpg'\n",
      " '1 (13).jpg' '1 (14).jpg' '1 (15).jpg' '1 (16).jpg' '1 (17).jpg'\n",
      " '1 (18).jpg' '1 (19).jpg' '1 (2).jpg' '1 (20).jpg' '1 (21).jpg'\n",
      " '1 (22).jpg' '1 (23).jpg' '1 (24).jpg' '1 (25).jpg' '1 (26).jpg'\n",
      " '1 (27).jpg' '1 (28).jpg' '1 (29).jpg' '1 (3).jpg' '1 (30).jpg'\n",
      " '1 (31).jpg' '1 (32).jpg' '1 (33).jpg' '1 (34).jpg' '1 (35).jpg'\n",
      " '1 (36).jpg' '1 (37).jpg' '1 (38).jpg' '1 (39).jpg' '1 (4).jpg'\n",
      " '1 (40).jpg' '1 (41).jpg' '1 (42).jpg' '1 (43).jpg' '1 (44).jpg'\n",
      " '1 (45).jpg' '1 (46).jpg' '1 (47).jpg' '1 (48).jpg' '1 (49).jpg'\n",
      " '1 (5).jpg' '1 (50).jpg' '1 (51).jpg' '1 (52).jpg' '1 (53).jpg'\n",
      " '1 (54).jpg' '1 (55).jpg' '1 (56).jpg' '1 (57).jpg' '1 (58).jpg'\n",
      " '1 (59).jpg' '1 (6).jpg' '1 (60).jpg' '1 (61).jpg' '1 (62).jpg'\n",
      " '1 (63).jpg' '1 (64).jpg' '1 (65).jpg' '1 (66).jpg' '1 (67).jpg'\n",
      " '1 (68).jpg' '1 (69).jpg' '1 (7).jpg' '1 (70).jpg' '1 (71).jpg'\n",
      " '1 (72).jpg' '1 (73).jpg' '1 (74).jpg' '1 (75).jpg' '1 (76).jpg'\n",
      " '1 (77).jpg' '1 (78).jpg' '1 (79).jpg' '1 (8).jpg' '1 (80).jpg'\n",
      " '1 (81).jpg' '1 (82).jpg' '1 (83).jpg' '1 (84).jpg' '1 (85).jpg'\n",
      " '1 (86).jpg' '1 (87).jpg' '1 (88).jpg' '1 (89).jpg' '1 (9).jpg'\n",
      " '1 (90).jpg' '1 (91).jpg' '1 (92).jpg' '1 (93).jpg' '1 (94).jpg'\n",
      " '1 (95).jpg' '1 (96).jpg' '1 (97).jpg' '1 (98).jpg' '1 (99).jpg'\n",
      " '2 (1).jpg' '2 (10).jpg' '2 (11).jpg' '2 (12).jpg' '2 (13).jpg'\n",
      " '2 (14).jpg' '2 (15).jpg' '2 (16).jpg' '2 (17).jpg' '2 (18).jpg'\n",
      " '2 (19).jpg' '2 (2).jpg' '2 (20).jpg' '2 (3).jpg' '2 (4).jpg' '2 (5).jpg'\n",
      " '2 (6).jpg' '2 (7).jpg' '2 (8).jpg' '2 (9).jpg']\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "r = []\n",
    "g = []\n",
    "b = []\n",
    "brightness = []\n",
    "label = []\n",
    "\n",
    "def colorfeatures(channel):\n",
    "    channel = np.array(channel)\n",
    "    channel = np.mat(channel)\n",
    "    channel = np.transpose(channel)\n",
    "    color = []\n",
    "    [h,l] = channel.shape\n",
    "    for i in range(l):\n",
    "        pixelVal = 0\n",
    "        pixel = 0\n",
    "        for j in range(h-30):\n",
    "            pixelVal+=channel[j,i]*(j+1)\n",
    "            pixel+=channel[j,i]\n",
    "        color.append(pixelVal/pixel)  \n",
    "    return color\n",
    "\n",
    "def sizefeatures(colonySize):\n",
    "    colonySize = np.array(colonySize)\n",
    "    colonySize = np.mat(colonySize)\n",
    "    colonySize = np.transpose(colonySize)\n",
    "    [h,l] =colonySize.shape\n",
    "    size=[]\n",
    "    for i in range(l):\n",
    "        count = 0\n",
    "        for j in range(h-30):\n",
    "            count+= colonySize[j,i]\n",
    "        size.append(count)\n",
    "    return size\n",
    "\n",
    "def Accuracy(a,y):\n",
    "    return (a==y)\n",
    "\n",
    "imagePath1 = 'colony1/'\n",
    "imagePath2 = 'colony2/'\n",
    "list1 = os.listdir(imagePath1)\n",
    "list2 = os.listdir(imagePath2)\n",
    "for file in list1:\n",
    "    if file != \"\":\n",
    "        img=cv2.imread(imagePath1+file)\n",
    "        brightness.append(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))  \n",
    "        r.append(cv2.calcHist([img], [0], None, [256], [0.0,255.0])) \n",
    "        g.append(cv2.calcHist([img], [1], None, [256], [0.0,255.0])) \n",
    "        b.append(cv2.calcHist([img], [2], None, [256], [0.0,255.0]))\n",
    "        label.append(0)\n",
    "for file in list2:\n",
    "    if(file !=\"\"):\n",
    "        img=cv2.imread(imagePath2+file)\n",
    "        brightness.append(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))  \n",
    "        r.append(cv2.calcHist([img], [0], None, [256], [0.0,255.0])) \n",
    "        g.append(cv2.calcHist([img], [1], None, [256], [0.0,255.0])) \n",
    "        b.append(cv2.calcHist([img], [2], None, [256], [0.0,255.0]))\n",
    "        label.append(1)\n",
    "\n",
    "colony = np.append(list1,list2)\n",
    "print(colony)\n",
    "print(label)\n",
    "for i in range(len(brightness)):\n",
    "    brightness[i]= brightness[i].mean()\n",
    "scalar = MinMaxScaler(feature_range=(0, 1))\n",
    "samples = np.c_[brightness,colorfeatures(r),colorfeatures(g),colorfeatures(b),sizefeatures(r)]\n",
    "#samples=samples.transpose()\n",
    "#print(samples)\n",
    "#samples=scalar.fit_transform(samples)\n",
    "#samples=samples.transpose()\n",
    "picList = np.c_[list1,range(len(list1))]\n",
    "d = DENCLUE(5, 0.5)\n",
    "d.classify(samples[:,1:4])\n",
    "a = d.clust_info_[0]['instances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong classification！\tpicture 1 (82).jpg :  Type II colony\n",
      "Wrong classification！\tpicture 1 (83).jpg :  Type II colony\n",
      "Wrong classification！\tpicture 1 (84).jpg :  Type II colony\n",
      "Wrong classification！\tpicture 1 (85).jpg :  Type II colony\n",
      "Wrong classification！\tpicture 1 (87).jpg :  Type II colony\n",
      "0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "out = []\n",
    "count = 0\n",
    "for i in range(len(colony)):\n",
    "        if i in a:\n",
    "            out.append(\"Type I colony\")\n",
    "            y = 0\n",
    "            if(Accuracy(label[i],y)):\n",
    "                count = count + 1\n",
    "            else:\n",
    "                print(\"Wrong classification！\\tpicture\",colony[i],\":  Type I colony\")\n",
    "        else:\n",
    "            out.append(\"Type II colony\")\n",
    "            y = 1\n",
    "            if(Accuracy(label[i],y)):\n",
    "                count = count + 1\n",
    "            else:\n",
    "                print(\"Wrong classification！\\tpicture\",colony[i],\":  Type II colony\")\n",
    "acc = count/len(colony)\n",
    "print(acc)\n",
    "column_name = ['picture','Type']\n",
    "out = np.c_[colony,out]\n",
    "dataFrame = pd.DataFrame(out,columns = column_name)\n",
    "dataFrame.to_excel(\"out.xls\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
